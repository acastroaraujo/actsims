---
output: github_document
editor_options: 
  chunk_output_type: console
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# actsims

<!-- badges: start -->
<!-- badges: end -->

`actsims` is an ACT package used for internal development of `interactShiny`

**It is not meant for public consumption.**

## Installation

However, if you must insist...

You can install the development version of actsims like so:

``` r
# install.packages("devtools")
devtools::install_github("acastroaraujo/actsims")
```

## Performance

-   `actsims` is meant to be fast and easy to use.
-   It uses the R6 OOP system to keep better track of EPA ratings and transient impression equations.
-   It is integrated with the `actdata` package.

Create an "InteRact" R6 object.

```{r example}
library(actsims)
suppressMessages(library(tidyverse))

act <- build_interact(dictionary = "usfullsurveyor2015", equation = "us2010")
act
```

This object comes with built in functions. 

Deflection scores.

```{r}
act$deflection(list(A = "deadbeat", B = "kill", O = "god"))
act$deflection(list(A = "deadbeat", B = "kill", O = "deadbeat"))
```

You can also extract useful metadata from these scores.

```{r}
d <- act$deflection(list(A = "ceo", B = "advise", O = "benefactor"))
d
get_fundamentals(d)
get_transients(d)
get_element_wise_deflection(d)
```

You can also do other stuff (more to come).

```{r}
act$reidentify_object(d)
```

## Many many

You can use a grid of events to estimate multiple deflection scores simultaneously.

For example, the following `events` object contains more than 2 million ABO events randomly created from the `usfullsurveyor2015` dictionary. 

```{r}
# create a grid of specific AB0s
events <- tidyr::crossing(
  A = act$dictionary |> dplyr::filter(component == "identity") |> dplyr::pull(term),
  B = act$dictionary |> dplyr::filter(component == "behavior") |> dplyr::pull(term) |> sample(3),
  O = act$dictionary |> dplyr::filter(component == "identity") |> dplyr::pull(term)
) 

glimpse(events)
```

Now you can repeat the earlier steps. 

```{r}
d <- act$deflection(events)
d
```

## Deference Score

You can also create the deference scores discussed by Freeland & Hoey (2018). But this requires to set up a new dictionary. 

Which you'll have to do with the help of external packages.

This is just way to do this. 

```{r}
occupation_ratings <- actdata::epa_subset(dataset = "occs2019") |> 
  dplyr::select(term, component, E, P, A) |> 
  dplyr::rename_all(tolower) |> 
  dplyr::rowwise() |> 
  dplyr::mutate(ratings = list(c(e = e, p = p, a = a))) |> 
  dplyr::ungroup() |> 
  dplyr::select(term, component, ratings)

occupation_ratings

defer_to <- act$dictionary |> 
  dplyr::filter(term == "defer_to")
```

Then you'll have to replace the original dictionary.

```{r}
act$dictionary <- dplyr::bind_rows(defer_to, occupation_ratings)
```

Note that a message appeared signaling that the replacement was succesful.

```{r}
act
```

Now you just create another grid of events, calculate the deflection scores, and average over the As.

```{r}
events <- crossing(
  A = occupation_ratings$term,
  B = "defer_to",
  O = occupation_ratings$term
)

output <- act$deflection(events)

output |> 
  filter(A != O) |> 
  group_by(A) |> 
  summarize(avg = mean(deflection)) |> 
  arrange(desc(avg)) 
```

