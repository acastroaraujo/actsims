---
output: github_document
editor_options: 
  chunk_output_type: console
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# actsims

<!-- badges: start -->
[![R-CMD-check](https://github.com/acastroaraujo/actsims/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/acastroaraujo/actsims/actions/workflows/R-CMD-check.yaml)
<!-- badges: end -->

-   `actsims` is an ACT package used for internal development of `interactShiny`

-   It is meant to be _fast_ and _easy_ to use.

-   It is integrated with the `actdata` package.

-   It uses the R6 OOP system to keep better track of EPA ratings and transient impression equations.

## Installation

You can install the development version of actsims like so:

``` r
# install.packages("devtools")
devtools::install_github("acastroaraujo/actsims")
```

## Usage

First, create an "`InteRactModel`" R6 object.

```{r example}
library(actsims)
suppressMessages(library(tidyverse))

act <- interact(dictionary = "usfullsurveyor2015", equations = "us2010")
act
```

_Dictionary_

```{r}
act$dictionary
```

_Equations_

```{r}
act$equations
```

`interact()` uses `group = all` by default for both equations and dictionaries. If this option does not exist in the `actdata` package, then you will see an error.

```{r, error=TRUE}
interact(dictionary = "indiana2003", equations = "nc1978")
```

You can change the defaults by specifying a second element in either argument. 

For example:

```{r}
interact(dictionary = "indiana2003", equations = list("nc1978", "male"))
```

## Methods

`InteRactModel` objects come with built in methods which you can access via the `$` operator. 

__Fundamentals.__

```{r}
act$fundamentals("mother")
```

_Note. This is just a simple function that looks inside `act$dictionary`_

__Deflection scores.__

```{r}
d <- act$deflection(data.frame(A = "god", B = "kill", O = "deadbeat"))
d
```

You can also extract useful metadata from these scores.

```{r}
get_fundamentals(d)
get_transients(d)
get_element_wise_deflection(d)
```

__Behaviors and Reidentification__

Optimal behaviors and/or reidentification uses the deflection scores estimated by `$deflection()` and stored in `d`. They require you specify the perspective of the one doing the behaving or the reidentifying.

Behaviors

```{r}
act$optimal_behavior(d, who = "actor")
act$optimal_behavior(d, who = "object")
```

Reidentification

```{r}
act$reidentify(d, who = "actor")
act$reidentify(d, who = "object")
```

__Solve For...__

```{r}
act$max_confirm(
  events = tibble(A = "god", O = "deadbeat"), 
  solve_for = "behavior"
) 

act$max_confirm(
  events = list(A = "god", B = "kill"), 
  solve_for = "object"
) 

act$max_confirm(
  events = data.frame(B = "kill", O = "deadbeat"), 
  solve_for = "actor"
) 

```

__Closest Terms__

```{r}
act$closest_terms(list(e = 1, p = 0, a = -1), component = "behavior", max_dist = 0.5)

deadbeat <- act$fundamentals("deadbeat")
deadbeat

act$closest_terms(deadbeat, component = "modifier", max_dist = 0.5)
```

## In Bulk...

You can use a grid of events to estimate multiple deflection scores simultaneously.

For example, the following `events` object contains 4 million ABO events randomly created from the `usfullsurveyor2015` dictionary. 

```{r}
# create a grid of specific AB0s
events <- tidyr::crossing(
  A = dplyr::filter(act$dictionary, component == "identity")[["term"]] |> sample(200),
  B = dplyr::filter(act$dictionary, component == "behavior")[["term"]] |> sample(100),
  O = dplyr::filter(act$dictionary, component == "identity")[["term"]] |> sample(200)
) 

glimpse(events)
```

Every method is designed to work in bulk. However, only the `$deflection()` method will work fast with millions of observations.

```{r}
d <- act$deflection(events)
d
get_fundamentals(d)
get_transients(d)
get_element_wise_deflection(d)
```

Other methods might require a minute or so...

```{r}
d_sub <- dplyr::slice_sample(d, n = 10000) # sample 10000 event deflections
d_sub
act$reidentify(d_sub, who = "actor")
act$optimal_behavior(d_sub, who = "actor")
act$reidentify(d_sub, who = "object")
act$optimal_behavior(d_sub, who = "object")

act$max_confirm(d_sub[c("A", "O")], solve_for = "behavior")
act$max_confirm(d_sub[c("A", "B")], solve_for = "object")
act$max_confirm(d_sub[c("B", "O")], solve_for = "actor")
```


## Deference Score

You can also create the deference scores discussed by Freeland & Hoey (2018). 

But this requires to modify the existing dictionary so we get the right combination of identities and behaviors.

This seems to be the easiest way to do this:

```{r}
occ <- interact(dictionary = "occs2019")
occ$dictionary

occupations <- occ$dictionary$term ## save for later use

defer_to <- act$dictionary |> 
  dplyr::filter(term == "defer_to")

## replace original dictionary
occ$dictionary <- dplyr::bind_rows(defer_to, occ$dictionary)
```

Note that a message appeared signaling that the replacement was successful.

```{r}
occ
```

Now you just create another grid of events, calculate the deflection scores, and average over the As.

```{r}
events <- tidyr::crossing(
  A = occupations,
  B = "defer_to",
  O = occupations
)

output <- occ$deflection(events)

output |> 
  group_by(A) |> 
  summarize(avg = mean(deflection)) |> 
  arrange(desc(avg)) 
```



